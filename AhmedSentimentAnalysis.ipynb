{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9f47fc-c14f-43ca-aecd-41c1380f33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76e01b4-b465-4401-94c1-ef9f6998d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tweet', 'label'],\n",
      "        num_rows: 4913\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"LYTinn/sentiment-analysis-tweet\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a494d2-791c-4231-bac4-5c3a98111b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(example):\n",
    "    label_mapping = {-1: 0, 0: 1, 1: 2}  # Map -1 to 0, 0 to 1, and 1 to 2\n",
    "    example['label'] = label_mapping[example['label']]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8915a042-8a23-49f7-a584-82df14bb0fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# # Initialize tokenizer and model\n",
    "# model_name = \"roberta-base\"\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "# model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming 3 labels (positive, negative, neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b74ca4-e5c9-4d67-a906-8a5ce266a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and tokenizer\n",
    "model_path = \"./sentiment-roberta\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71b9424a-a2b8-4107-847f-5f4009f6593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['tweet'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0498ebe1-0aae-4ca3-9769-f0ab3fd49a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the dataset once\n",
    "# shuffled_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "\n",
    "# # Split into train and validation sets\n",
    "# train_dataset = shuffled_dataset.select(range(8000))  # First 8000 samples for training\n",
    "# valid_dataset = shuffled_dataset.select(range(8000, 10000))  # Next 2000 samples for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8faa3a67-0c7b-4d22-b74d-29d39e3cb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Example: Splitting using train_test_split\n",
    "train_valid_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_valid_split[\"train\"]\n",
    "valid_dataset = train_valid_split[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d1de1f-3768-4edc-a3d5-6a5473133e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack logits and labels\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits to predictions on CPU\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=1).cpu()\n",
    "\n",
    "    # Convert labels to CPU if they are not already\n",
    "    labels = torch.tensor(labels).cpu()\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04598e0a-f15a-46e8-8776-e8bcd7b9c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "# Move model to the device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c87c3ed-98d4-4036-8667-e20c14ce8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "682bb198-d3ba-4011-973d-ac00a842c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c1d910a-7fd2-44cc-9a57-b40abb7cebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 06:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.263200</td>\n",
       "      <td>0.072240</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.983258</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.31231107711791994, metrics={'train_runtime': 413.7402, 'train_samples_per_second': 19.336, 'train_steps_per_second': 2.417, 'total_flos': 2104907341824000.0, 'train_loss': 0.31231107711791994, 'epoch': 1.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model from the last checkpoint\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd3e7a1-ee1a-4a6d-9a77-cb2dc332319e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.07224017381668091, 'eval_accuracy': 0.983, 'eval_f1': 0.9830409807283051, 'eval_precision': 0.983257554532163, 'eval_recall': 0.983, 'eval_runtime': 30.7049, 'eval_samples_per_second': 65.136, 'eval_steps_per_second': 8.142, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dfbeb25-0763-4944-a74e-563bda9e6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment-roberta\\\\tokenizer_config.json',\n",
       " './sentiment-roberta\\\\special_tokens_map.json',\n",
       " './sentiment-roberta\\\\vocab.json',\n",
       " './sentiment-roberta\\\\merges.txt',\n",
       " './sentiment-roberta\\\\added_tokens.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./sentiment-roberta\")\n",
    "tokenizer.save_pretrained(\"./sentiment-roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d29d-ee9a-426c-ba47-83eb419b6fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b296375-d733-47cf-a9b3-b338e5c1612d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b879042-e0fc-4101-be5d-1e8f4685fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"fulldata.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043a98a4-160a-4967-95a5-5611cc33dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the text column is properly named\n",
    "text_column = \"comment\"\n",
    "assert text_column in df.columns, f\"'{text_column}' column not found in CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bd4245-88b8-47be-af1f-5d9dff52e2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model and tokenizer\n",
    "model_path = \"./sentiment-roberta\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76579223-b70f-4859-9b2f-c26f72e45820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a7d4f3-5eb2-4001-a732-4b3e3d908b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize input and move to the correct device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    \n",
    "    # Ensure model is on the same device as inputs\n",
    "    model.to(device)\n",
    "    \n",
    "    # Predict without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66682b0d-7c7d-49ff-9928-610442ad0298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 1, 2, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Small Subset Debugging: Processes a few rows to confirm the function works correctly before applying it to the entire dataset.\n",
    "sample_texts = df[text_column].head(10).tolist()  # Get the first 10 rows\n",
    "predictions = [predict_sentiment(text) for text in sample_texts]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d31940c-4efc-4faf-8ba4-057e3912bd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What is that suit fit my Mamba. Miss you man. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Fuck I want to be in New Zealand, America kind of sucks right now in every way \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: How did you get the eggs so perfect?? \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Momo Jenga \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: This is surprisingly wholesome \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I can't wait to see CS:GO gameplay on toilets \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I love my Lakers. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: /r/AccidentalRenaissance  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Where‚Äôs the brew? \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: omg so aesthetically pleasing to look at, wondering what was in those dessert cups... \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Now where's that video of the japanese guy with a really big and pillow-y enter key \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: The people that need to hear this message won‚Äôt listen and the people that need others to hear it have been screaming it at the top of their lungs for a long time \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Well japan is right the U.S. isn‚Äôt taking it seriously..look at the number of cases Japan has compared to U.S....hey Americans, wear a god damn fuckng mask when you‚Äôre in public.. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Wait.. Are those swords in the background.. That's quite a collection!  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Let them try to stop me from voting. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Anyone else get sad as fuck when you're eating delicious wings and you look close and see little hairs all over? \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: This is just propaganda to force low income kids into middle/high income public schools. If you cant volunteer or donate to the school your kid is going to but you want all the nice things that come with that, that's not my issue.  \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: These were the best Lego games. Even the new one doesn‚Äôt feel the same with ‚Äúmumble mode‚Äù just because all of those scenes were still very obviously made with voice lines in mind. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: [You made this?](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSN0xq1BhlRwVCmKn4yuGdr_8r6HxwpddwxpcVagHvfEvdtp-qtUckL1IGL&s=10)   ...I made this. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: I started learning to code 8 years ago.  I also stopped learning 8 years ago........ \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Adding a Susan Sussler story on the family, from the off-season. [A‚Äôs Stephen Piscotty helps mom cope with ALS](https://www.sfchronicle.com/athletics/article/A-s-Stephen-Piscotty-helps-mom-cope-with-ALS-12526502.php) \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Biden wasn't my first pick in the primaries but compared to Trump he's great. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Give \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Fucking good -- at this point they're seditious terrorists. If you plan, plot, and execute undermining the government you shouldn't be deserving of security clearances. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: [I wonder if he was writing a test for his grade 10](https://youtu.be/koR2uJWrUuQ) \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: I wonder if Pence has ever heard about that Israeli Jew who walked around decrying the rich and helping the poor. I think his name was Jesus or something... \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Rip out your lawns then plant milkweed and native wildflowers. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: It‚Äôs actually kind of amazing how effective the campaign has been to overcome science on this issue.  If you‚Äôd asked me ahead of time, I would not have believed you could get people to adopt this as a purely political question.  But they did it. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: My friends father was an auditor working at the state level in New York in the 80's and 90's. He found discrepancies in the agency he was auditing, and his direct supervisor told him that unless he'd like to end up in the bottom of a river he would do well to un-find said discrepancies. That was when he knew that he would have the job for 30 years and never have to work a day. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Is she single? \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: How did you make it with no knowledge of code OP? \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Seems like a lifetime away until we can do this \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: What is going on with high school athletes these days. Dunking from the free throw line, doing shit like this. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Looks like he tore his ACEcl \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I like your balls \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I have those same paper plates! \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Abolish the GOP \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: This is how you fight the right-wing propaganda/bullshit system.  You make it financially crippling to spread their shit. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: That looks like a very tasty post-it note casserole. Cheers to your grandma!  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: OMG. Those look devine. Blueberry is always my favorite. Is this receipe gelatin free? Recently stopped eating meat so can't eat name brand poptarts. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: https://twitter.com/ChrisMegerian/status/1310335926120390656  > **The president pays more in taxes to foreign governments than to the United States.**  > $750 to the I.R.S., $15,598 to Panama, $145,400 to India and $156,824 to the Philippines. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Living legend, met him two different times he‚Äôs a great dude \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: $$$ talks! \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: How cute. And creative! Well done \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: oooOooh these look GOOD! üòãüçãüç™‚ù§Ô∏èüòç \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I don‚Äôt eat seafood and this looks amazing.  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Free game is free game \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Trump/Pence: My job here is done  Everyone: Fucking finally \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I think the announcers being prepared with masks/umbrellas started later in his career --- so it all probably happened gradually.  But Jordan would laugh frequently when they went all out.  I miss watching him play -- always looked forward to that moment.  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Happens more often than you think. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Wonder what kind of disaster it will take for the Bills to win the Superbowl...  Go Astros though - can't imagine how that city must feel right now. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Just here to downvote all the obnoxious comments grandstanding about uniforms \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I want to see this.  I went to oranges twitter and don't see the messages from Twitter... Anyone able to screenshot this?? Just wanting to keep track of all the nails we are placing in his presidencies coffin. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: You had a printer. I had physical books.   I remember the last walkthrough book I purchased for FFIX, and iirc it had bonus info online for a price.  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: /r/childrenfallingover  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Beautiful work! \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Screen shot this and I‚Äôll have a go tomorrow or Friday, just got into cooking and love these, so good practice, I‚Äôll post mine when done !   Thanks they look yummy btw  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: Multiple times a day living in San Jose/Bay Area. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Yes, please. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Harden used harden. It was not very effective... \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: For a cell/disease that results from 'mistakes' in the functioning of the cell and its genetic code, cancer seems to almost be a highly evolved biological system in and of itself. Can our normal cells do this?.. just 'hibernate' when they think they're under attack?      When a type of cancer is identified, is the specific genetic damage that caused the cell to turn cancerous always the same type of damage? That would seem strange to me but I don't know the ins and outs of biology that well. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Chill on the dressing.  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Now we're talking.  Stop going after the people who are just making what their parents made, adjusted for inflation.   Get the assholes who robbed the world by underpaying employees, raiding pension funds on Wall Street, and forcing the public to clean up their toxic waste sites and bail out their failed companies. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: the fuck, 128k upvotes for this shit \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I desperately want to see the inside  \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Jesus, hes lucky that mass didnt break his back.  That guy's neck looks like a pack of bratwurst \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I'm gonna get me a New York slice! \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: This is beautiful, and your name is master_mom, for real, master of just beautiful things. In such awe right now.... \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: What kind of ramen are you buying? That stuff has never poured out of any of my flavor packets.  \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Its a common celebration to jump into the arms of a teammate.   \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: YUMMM üòçüòçüòç \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: What do you do when you finish a painting or a sculpture? \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Meanwhile the evil empire known as the Yankees rubs their hands...they will throw money at Astros players and lure them to the dark side \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Competition is such a strong word for Epic Games.  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I'm a male in medicine. Despite the majority of new doctors being female now, females are still celebrated and encouraged to apply to medical programmes, despite constituting the majority of students and new graduates (for the last decade or so, according to our med school).   Furthermore, I feel the 'culture' of how men are treated around children and female patients here... We're seen as prospective predators and we're constantly reminded about how we need to 'protect ourselves' by having chaperones. Female students NEVER encounter such dialogue... We're also bombarded with anecdotes from doctors about males being falsely accused of inappropriate conduct to scare us into, essentially, employing a personal chaperone or totally avoiding female patients all together. I really don't feel comfortable at times in this career path... \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: They should make two covers one with 24 and one with eight \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Remember, when Republicans say \"Never Forget 9/11\", they don't mean to never forget the heroism of the first responders, because they legitimately could not care less about them.  They mean \"Never Forget\" that we were attacked by Muslims.  All they want is for our country to live in endless fear. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Agreed. Why do the hearings if we won‚Äôt hold people accountable to what is said in them? \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: ‚ÄúDada!‚Äù  HEARTS: COMMENCE MELTING.  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: I live for these kinds of things \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I deleted mine years ago. Where's my 102 plus interest? \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I'm too high for this. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: Thanks for the clarification, I was wondering how it was the world record when Eddie Hall pulled 1100 lbs.   I'm going to look up this \"elephant bar\".  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: I just need to tell you that I HATE this \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Fun fact: Skyrim is the first TES game to have an Elder Scroll be involved in the main quest.  You only get an Elder Scroll in Oblivion during the Thieves Guild Questline. \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: That was done pretty well! I looked like it was stuck to his hand \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: I swear I can almost smell and taste this picture omg. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: You are my angel and I love your food. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: He wants to make it more difficult to discern who is a cop and who is a militia member. Textbook prelude to civil war \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: And they don‚Äôt stop coming  And they don‚Äôt stop coming  And they don‚Äôt stop coming \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Our president is an imbecile \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Serious question because I‚Äôm genuinely confused with what the goal is. When all of the quarantining started, everyone would say ‚Äúwe are doing this not to find a cure, but to flatten the curve and not overload our medical system.‚Äù But now it‚Äôs ‚Äúwe‚Äôre doing this until there‚Äôs a cure.‚Äù Which is it? I‚Äôm all for vaccines and quarantining, but I was under the impression we‚Äôre just trying to flatten the curve and NOT rely solely on the idea of finding a vaccine, considering it took 50-60 years to find one for polio. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: r/whitepeoplegifs  \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: And this comes after Trump removed the independent oversight for coronavirus funds.  [https://www.politico.com/news/2020/04/07/trump-removes-independent-watchdog-for-coronavirus-funds-upending-oversight-panel-171943](https://www.politico.com/news/2020/04/07/trump-removes-independent-watchdog-for-coronavirus-funds-upending-oversight-panel-171943)  This is getting fishier by the second. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Oh my god it's happening. Everybody stay calm. EVERYBODY STAY CALM \n",
      "Predicted Sentiment: Neutral\n",
      "\n",
      "Text: This is one of my favorite things ever.  \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: The top of my mouth hurts looking at this pic. \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Text: Hopefully you shared lol, nice food tho \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I make a wicked butter chicken paneer. My bf says its his new favorite dish besides tacos. (He LOVES his tacos) . This looks amazing. GOALS. \n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Text: I know is a wrong approach for hacking. But sometimes damn it shit just gets so tiring with these hate groups. Thank you Anonymous!  Thank you for fighting for humanity‚Äôs rights! üëèüëè \n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Total Processing Time: 2.75 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define a mapping for predicted labels to sentiment for a better understanding\n",
    "label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "# Start timing the process\n",
    "start_time = time.time()\n",
    "\n",
    "# Get random 500 rows\n",
    "sample_texts = df[text_column].sample(n=100, random_state=40).tolist()\n",
    "\n",
    "# Predict sentiment for each text\n",
    "predictions = [predict_sentiment(text) for text in sample_texts]\n",
    "\n",
    "# Print both the text and its predicted sentiment label\n",
    "for text, pred in zip(sample_texts, predictions):\n",
    "    sentiment = label_mapping.get(pred, \"Unknown Yet\")\n",
    "    print(f\"Text: {text} \\nPredicted Sentiment: {sentiment}\\n\")\n",
    "\n",
    "# End timing the process\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the processing time\n",
    "processing_time = end_time - start_time\n",
    "print(f\"Total Processing Time: {processing_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85673323-50cf-45f1-a796-4084d55bb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Remove Rows with Missing or Invalid Data\n",
    "# Use this for the datasets which we didn't do fine-tuning on it.\n",
    "\n",
    "df = df.dropna(subset=[text_column])\n",
    "df[text_column] = df[text_column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c66ab4f-ada5-48d4-bd1c-1dc48cebe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the prediction function to the text column\n",
    "df[\"predicted_label\"] = df[text_column].apply(predict_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "753428ee-2d79-4191-b90d-f7b75d843954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to sentiment_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the results\n",
    "output_file = \"sentiment_predictions.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092b9c0-96bf-4a2e-b580-95ec271369d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
